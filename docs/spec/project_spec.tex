\documentclass[10pt]{article}

\usepackage{enumerate,graphicx}
\usepackage{../durhampaper}
\usepackage{harvard}

\pagestyle{empty}


\citationmode{abbr}
\bibliographystyle{agsm}

\begin{document}

\newcommand{\bi}{\begin{itemize}}
\newcommand{\ei}{\end{itemize}}

\section*{Generative Models for Information Security}

\bigskip

\noindent {\bf Degree:} MEng. Computer Science \\
\\ 
{\bf Student:} John Jennings  \hspace{3mm} {\bf Supervisor:} Chris Willcocks \\
\\ 
{\bf Description:} \vspace{1mm} \\
Generative models, particularly Generative Adversarial Networks (GANs), are important tools in machine learning, seeing recent success in a wide variety of applications, from synthesizing realistic images of human faces and house interiors, to transforming photos from summer to winter and night to day. Within the information security sector, GANs have been used for learning novel encryption schemes, modelling password distributions, and steganography techniques for hiding information within an image. This project will expand upon current research, and investigate the applications of machine learning to lexical steganography - the practice of hiding a hidden message within a `cover text'.\\
\\
{\bf Preliminary Preparation:}
  \begin{itemize}
    \item Collection of an appropriate dataset of cover texts e.g. BBC News articles, tweets, Wikipedia articles
    \item Survey of existing methods for lexical steganography with focus on machine learning applications, as well as methods for attacking these stegosystems.
  \end{itemize}
{\bf Minimum Objectives:}
  \begin{itemize}  
    \item Simple autoencoder-inspired network takes cover text and message as input. Encoder aims to embed message within cover text, decoder aims to extract the embedded message. Loss function is a combination of reconstruction error of decoder with respect to original message and reconstruction error of encoder with respect to the cover text, where `reconstruction error' takes into account semantic coherence through the use of pre-trained word embeddings.
    \item Comparison of this network against existing methods e.g. TLex, LUNABEL.
    \item Users will be able to interact with the system through a web interface, embedding their own message into a cover text of their choice.
  \end{itemize}
{\bf Intermediate Objectives:}
  \begin{itemize}  
    \item Encoder output will be robust to random deletion of words/sentences i.e. hidden message can still be decoded from partial output.
    \item Encoder will be robust to an adversarial network attempting to identify if the output text contains a hidden message.
    \item Encoder will additionally take a random key as input. Will be robust to an adversarial network attempting to decode the hidden message without knowledge of the key.
  \end{itemize}
{\bf Advanced Objectives:}
  \begin{itemize}  
    \item Cryptanalysis of system to give some theoretical bounds on the level of security that is provided e.g. Does partial knowledge of the key yield a partially decoded message? How much information can be successfully hidden within a typical sentence?
  \end{itemize}

\nocite{*}
\bibliography{../bib}
\end{document} 